{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rippl_AI\n",
    "import importlib\n",
    "importlib.reload(rippl_AI)\n",
    "import aux_fcn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib qt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section A\n",
    "In this section, a use example of the predict and detection functions are provided"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data... Please wait, this might take up some time\n",
      "Data downloaded!\n"
     ]
    }
   ],
   "source": [
    "from figshare.figshare.figshare import Figshare\n",
    "fshare = Figshare()\n",
    "\n",
    "article_ids = [14959449] \n",
    "sess=['Dlx1']                                  \n",
    "for id,s in zip(article_ids,sess):\n",
    "    datapath = os.path.join('Downloaded_data', f'{s}')\n",
    "    if os.path.isdir(datapath):\n",
    "        print(\"Data already exists. Moving on.\")\n",
    "    else:\n",
    "        print(\"Downloading data... Please wait, this might take up some time\")        # Can take up to 10 minutes\n",
    "        fshare.retrieve_files_from_article(id,directory=datapath)\n",
    "        print(\"Data downloaded!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel map value:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Downloaded_data\\Dlx1\\figshare_14959449/lfp_Dlx1-2021-02-12_12-46-54.dat\n",
      "fileStart  0\n",
      "fileStop  490242048\n",
      "nSamples  245121024\n",
      "nSamplesPerChannel  30640128\n",
      "nSamplesPerChunk  10000\n",
      "size data  30640128\n",
      "Sampling frequency:  30000\n",
      "Shape of the original data (30640128, 8)\n",
      "[[1 1 2]\n",
      " [2 1 2]\n",
      " [3 1 2]\n",
      " [4 1 2]\n",
      " [5 1 2]\n",
      " [6 1 2]\n",
      " [7 1 2]\n",
      " [8 1 2]]\n"
     ]
    }
   ],
   "source": [
    "path=os.path.join('Downloaded_data','Dlx1','figshare_14959449')\n",
    "\n",
    "sf, expName, ref_channels, dead_channels = aux_fcn.load_info(path)\n",
    "channels_map = aux_fcn.load_channels_map(path)\n",
    "\n",
    "# Reformat channels into correct values\n",
    "channels, shanks, ref_channels = aux_fcn.reformat_channels(channels_map, ref_channels)\n",
    "# Read .dat\n",
    "print('Channel map value: ',channels)\n",
    "LFP = aux_fcn.load_raw_data(path, expName, channels, verbose=True)\n",
    "print('Sampling frequency: ', sf)\n",
    "print('Shape of the original data',LFP.shape)\n",
    "print(channels_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predict function takes care of normalizing and subsampling your data\n",
    "# If no architecture or model is specified, the best CNN1D will be used\n",
    "prob,LFP_norm=rippl_AI.predict(LFP,sf) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "det_ind=rippl_AI.get_intervals(prob,LFP_norm=LFP_norm)  # Problem: must be executed twice to choose the threshols\n",
    "                                      # 1: launch, choose th, save\n",
    "                                      # 2: lauch again, any  th. The previous th will be saved\n",
    "print(f\"{det_ind.shape[0]} events where detected\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section B\n",
    "Every model predict, get_intervals is used automatically and the performance metric is ploted"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from figshare.figshare.figshare import Figshare\n",
    "fshare = Figshare()\n",
    "\n",
    "article_ids = [14959449] \n",
    "sess=['Dlx1']                                    \n",
    "for id,s in zip(article_ids,sess):\n",
    "    datapath = os.path.join('Downloaded_data', f'{s}')\n",
    "    if os.path.isdir(datapath):\n",
    "        print(\"Data already exists. Moving on.\")\n",
    "    else:\n",
    "        print(\"Downloading data... Please wait, this might take up some time\")        # Can take up to 10 minutes\n",
    "        fshare.retrieve_files_from_article(id,directory=datapath)\n",
    "        print(\"Data downloaded!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Channel map value:  [0, 1, 2, 3, 4, 5, 6, 7]\n",
      "Downloaded_data\\Dlx1\\figshare_14959449/lfp_Dlx1-2021-02-12_12-46-54.dat\n",
      "fileStart  0\n",
      "fileStop  490242048\n",
      "nSamples  245121024\n",
      "nSamplesPerChannel  30640128\n",
      "nSamplesPerChunk  10000\n",
      "size data  30640128\n",
      "Sampling frequency:  30000\n",
      "Shape of the original data (30640128, 8)\n"
     ]
    }
   ],
   "source": [
    "path=os.path.join('Downloaded_data','Dlx1','figshare_14959449')\n",
    "\n",
    "sf, expName, ref_channels, dead_channels = aux_fcn.load_info(path)\n",
    "\n",
    "channels_map = aux_fcn.load_channels_map(path)\n",
    "# Now the ground truth (GT) tagged events is loaded \n",
    "ripples=aux_fcn.load_ripples(path)/sf\n",
    "# Reformat channels into correct values\n",
    "channels, shanks, ref_channels = aux_fcn.reformat_channels(channels_map, ref_channels)\n",
    "# Read .dat\n",
    "print('Channel map value: ',channels)\n",
    "LFP = aux_fcn.load_raw_data(path, expName, channels, verbose=True)\n",
    "print('Sampling frequency: ', sf)\n",
    "print('Shape of the original data',LFP.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Two loops going over every possible model\n",
    "architectures=['XGBOOST','SVM','LSTM','CNN1D','CNN2D']\n",
    "SWR_prob=[[None]*5]*5\n",
    "for i,architecture in enumerate(architectures):\n",
    "    print(i,architecture)\n",
    "    for n in range(1,6):\n",
    "        # Make sure the selected model expected number of channels is the same as the channels array passed to the predict fcn\n",
    "        # In this case, we are manually setting the channel array to 3 \n",
    "        if architecture=='CNN2D' and n>=3:\n",
    "            channels=[0,3,7]\n",
    "        else:\n",
    "            channels=[0,1,2,3,4,5,6,7]\n",
    "        SWR_prob[i][n-1],_=rippl_AI.predict(LFP,sf,arch=architecture,model_number=n,channels=channels)\n",
    "\n",
    "# SWR_prob contains the output of each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "th_arr=np.linspace(0.1,1,10)\n",
    "fig,axs=plt.subplots(5,5,figsize=(10,10),sharex='all',sharey='all')\n",
    "for i in range(5):\n",
    "    for j in range(5):\n",
    "        F1_arr=np.zeros(shape=(len(th_arr)))\n",
    "        for k,th in enumerate(th_arr):\n",
    "            det_ind=rippl_AI.get_intervals(SWR_prob[i][j],threshold=th)\n",
    "            #print(ripples)\n",
    "            _,_,F1_arr[k],_,_,_=aux_fcn.get_performance(det_ind,ripples)\n",
    "        axs[i,j].plot(th_arr,F1_arr)\n",
    "    axs[i,0].set_title(architectures[i])\n",
    "\n",
    "axs[0,0].set_xlabel('Threshold')\n",
    "axs[0,0].set_ylabel('F1')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section C\n",
    "In this section how to use the interpolation function is used will be shown. It is generally called internally from LFP_predict(), which could cause some confusion"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data already exists. Moving on.\n"
     ]
    }
   ],
   "source": [
    "from figshare.figshare.figshare import Figshare\n",
    "fshare = Figshare()\n",
    "\n",
    "article_ids = [14959449] \n",
    "sess=['Dlx1']                                    \n",
    "for id,s in zip(article_ids,sess):\n",
    "    datapath = os.path.join('Downloaded_data', f'{s}')\n",
    "    if os.path.isdir(datapath):\n",
    "        print(\"Data already exists. Moving on.\")\n",
    "    else:\n",
    "        print(\"Downloading data... Please wait, this might take up some time\")        # Can take up to 10 minutes\n",
    "        fshare.retrieve_files_from_article(id,directory=datapath)\n",
    "        print(\"Data downloaded!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load\n",
    "To ilustrate how 'interpolate_channels' can be used to extract the desired number of channels, we will be simulating two cases using the DLx1 session:\n",
    "1. We are using a recording probe that extracts 4 channels, when we need 8.\n",
    "2. Some channels are dead or have to much noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=os.path.join('Downloaded_data','Dlx1','figshare_14959449')\n",
    "\n",
    "sf, expName, ref_channels, dead_channels = aux_fcn.load_info(path)\n",
    "\n",
    "channels_map = aux_fcn.load_channels_map(path)\n",
    "channels, shanks, ref_channels = aux_fcn.reformat_channels(channels_map, ref_channels)\n",
    "LFP = aux_fcn.load_raw_data(path, expName, channels, verbose=False)\n",
    "print('Sampling frequency: ', sf)\n",
    "print('Shape of the original data',LFP.shape)\n",
    "LFP_linear=LFP[:,[0,2,4,6]]\n",
    "print('Shape of the 4 channels simulated data: ',LFP_linear.shape)\n",
    "LFP[:,[2,5]]=0\n",
    "LFP_dead=LFP\n",
    "print('Sample of the simulated dead LFP: ',LFP_dead[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After interpolation, the data is ready to use in prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define channels\n",
    "channels_interpolation = [0,-1,1,-1,2,-1,-1,3]\n",
    "\n",
    "# Make interpolation\n",
    "LFP_interpolated = aux_fcn.interpolate_channels(LFP_linear, channels_interpolation)\n",
    "print('Shape of the interpolated LFP: ',LFP_interpolated.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Define channels\n",
    "channels_interpolation = [0,1,-1,3,4,-1,6,7]\n",
    "\n",
    "# Make interpolation\n",
    "LFP_interpolated = aux_fcn.interpolate_channels(LFP_dead, channels_interpolation)\n",
    "print('Value of the 1st sample of the interpolated LFP: ',LFP_interpolated[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section D\n",
    "In this section an ensemble model that combines the output of the other 5 previous models will be shown. In this case, only the best ensemble model will be provided.\n",
    "\n",
    "First, the output of the 5 selected models needs to reshaped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampling data at 1250 Hz...\n",
      "Shape of downsampled data: (1276672, 8)\n",
      "Normalizing data...\n",
      "XGBOOST_1_Ch8_W60_Ts016_D7_Lr0.10_G0.25_L10_SCALE1\n",
      "Downsampling data at 1250 Hz...\n",
      "Shape of downsampled data: (1276672, 8)\n",
      "Normalizing data...\n",
      "SVM_1_Ch8_W60_Ts001_Us0.05\n",
      "Downsampling data at 1250 Hz...\n",
      "Shape of downsampled data: (1276672, 8)\n",
      "Normalizing data...\n",
      "LSTM_1_Ch8_W60_Ts32_Bi0_L4_U11_E10_TB256\n",
      "1247/1247 [==============================] - 8s 6ms/step\n",
      "Downsampling data at 1250 Hz...\n",
      "Shape of downsampled data: (1276672, 8)\n",
      "Normalizing data...\n",
      "CNN1D_1_Ch8_W60_Ts16_OGmodel12\n",
      "2494/2494 [==============================] - 2s 785us/step\n",
      "Downsampling data at 1250 Hz...\n",
      "Shape of downsampled data: (1276672, 8)\n",
      "Normalizing data...\n",
      "CNN2D_1_Ch8_W60_Ts40_OgModel\n",
      "998/998 [==============================] - 3s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# 5 outputs are generated\n",
    "architectures=['XGBOOST','SVM','LSTM','CNN1D','CNN2D']\n",
    "output=[]\n",
    "for architecture in architectures:\n",
    "    channels=[0,1,2,3,4,5,6,7]\n",
    "    SWR_prob,_=rippl_AI.predict(LFP,sf,arch=architecture,model_number=1,channels=channels)\n",
    "    output.append(SWR_prob)\n",
    "ens_input=np.array(output).transpose()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating ensemble model output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39896/39896 [==============================] - 19s 481us/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prob_ens=rippl_AI.predict_ens(ens_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision = 0.6297376093294461\n",
      "recall = 0.8293838862559242\n",
      "F1 = 0.7159023115311409\n",
      "precision = 0.7204301075268817\n",
      "recall = 0.7819905213270142\n",
      "F1 = 0.7499491214978631\n",
      "precision = 0.7258687258687259\n",
      "recall = 0.7488151658767772\n",
      "F1 = 0.7371634197791289\n",
      "precision = 0.7386363636363636\n",
      "recall = 0.7298578199052133\n",
      "F1 = 0.7342208530458063\n",
      "precision = 0.746268656716418\n",
      "recall = 0.7061611374407584\n",
      "F1 = 0.725661130862514\n",
      "precision = 0.7942386831275721\n",
      "recall = 0.6729857819905214\n",
      "F1 = 0.7286020018875701\n",
      "precision = 0.8401639344262295\n",
      "recall = 0.6635071090047393\n",
      "F1 = 0.7414583737001873\n",
      "precision = 0.8518518518518519\n",
      "recall = 0.6255924170616114\n",
      "F1 = 0.7213971723892124\n",
      "precision = 0.8875502008032129\n",
      "recall = 0.5971563981042654\n",
      "F1 = 0.7139542337029676\n",
      "x is empty. Cant perform IoU\n",
      "precision = nan\n",
      "recall = 0.0\n",
      "F1 = nan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Adrian\\miniconda3\\envs\\PublicBCG_d\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3464: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "c:\\Users\\Adrian\\miniconda3\\envs\\PublicBCG_d\\lib\\site-packages\\numpy\\core\\_methods.py:192: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'F1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "th_arr=np.linspace(0.1,1,10)\n",
    "F1_arr=np.zeros(shape=(len(th_arr)))\n",
    "for k,th in enumerate(th_arr):\n",
    "    det_ind=rippl_AI.get_intervals(prob_ens,threshold=th)\n",
    "    _,_,F1_arr[k],_,_,_=aux_fcn.get_performance(det_ind,ripples)\n",
    "ax.plot(th_arr,F1_arr)\n",
    "ax.set_title('Ensemble model')\n",
    "ax.set_ylim(-0.05,0.8)\n",
    "ax.set_xlabel('Threshold')\n",
    "ax.set_ylabel('F1')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PublicBCG_d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
