{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSTM parameter exploration\n",
    "This notebook is a template for finding the LSTM model best suited for your needs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "import sys\n",
    "parent_dir=os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0,parent_dir)\n",
    "import rippl_AI\n",
    "import aux_fcn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download\n",
    "4 uLED sessions will be downloaded: Amigo2 and Som2 will be used for training ; Dlx1 and Thy7 for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from figshare.figshare.figshare import Figshare\n",
    "fshare = Figshare()\n",
    "\n",
    "article_ids = [16847521,16856137,14959449,14960085] \n",
    "sess=['Amigo2','Som2','Dlx1','Thy7']                                  \n",
    "for id,s in zip(article_ids,sess):\n",
    "    datapath = os.path.join(parent_dir,'Downloaded_data', f'{s}')\n",
    "    if os.path.isdir(datapath):\n",
    "        print(f\"{s} session already exists. Moving on.\")\n",
    "    else:\n",
    "        print(\"Downloading data... Please wait, this might take up some time\")        # Can take up to 10 minutes\n",
    "        fshare.retrieve_files_from_article(id,directory=datapath)\n",
    "        print(\"Data downloaded!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load\n",
    "The training sessions' LFP will be appended together in a list. The same will happen with the ripples detection times.\n",
    "That is the required input for the training parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training sessions will be appended together. Replace this cell with your own data loading\n",
    "train_LFPs=[]\n",
    "train_GTs=[]\n",
    "# Amigo2\n",
    "path=os.path.join(parent_dir,'Downloaded_data','Amigo2','figshare_16847521')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "train_LFPs.append(LFP)\n",
    "train_GTs.append(GT)\n",
    "# Som2\n",
    "path=os.path.join(parent_dir,'Downloaded_data','Som2','figshare_16856137')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "train_LFPs.append(LFP)\n",
    "train_GTs.append(GT)\n",
    "\n",
    "## Append all your validation sessions\n",
    "val_LFPs=[]\n",
    "val_GTs=[]\n",
    "# Dlx1 Validation\n",
    "path=os.path.join(parent_dir,'Downloaded_data','Dlx1','figshare_14959449')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "val_LFPs.append(LFP)\n",
    "val_GTs.append(GT)\n",
    "# Thy07 Validation\n",
    "path=os.path.join(parent_dir,'Downloaded_data','Thy7','figshare_14960085')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "val_LFPs.append(LFP)\n",
    "val_GTs.append(GT)\n",
    "\n",
    "x_training,GT_training,x_val_list,GT_val_list=rippl_AI.prepare_training_data(train_LFPs,train_GTs,val_LFPs,val_GTs,sf=30000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM training parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters:\n",
    "* Channels:  number of channels that will be used to train the model, extracted from the data shape defined in the previous cell\n",
    "* Timesteps: number of samples that the will be processed at once\n",
    "* Bidirectionality: if the model processes simutaneously the window forward and backwards\n",
    "* Layers: number of LSTM layers\n",
    "* Epoch: number of times the training data set is used to train the model\n",
    "* Training batch: number of windows that are proccessed before weight updating\n",
    "\n",
    "#\n",
    "LSTM contains more parameters, feel free to add your own modifications. Check the oficial documentation:\n",
    "https://keras.io/api/layers/recurrent_layers/lstm/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf=   {\"timesteps\":[15,40],       # 8,16,40 ...\n",
    "        \"bidirectional\": [0],       # 0 or 1\n",
    "        \"layers\": [1,2],            # 2,3,4\n",
    "        \"units\": [10],              # 5,6,10,12...\n",
    "        \"epochs\": [2],              # 1,2,3...\n",
    "        \"train_batch\": [2**8]}      # 16,32,64 (Powers of two are recommended for computacional efficiency)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired sampling frequency of the models\n",
    "sf=1250\n",
    "th_arr=np.linspace(0.1,0.9,9)\n",
    "model_name_arr=[]           # To plot in the next cell\n",
    "model_arr=[]                # Actual model array, used in the next validation section\n",
    "n_channels=x_training.shape[1]\n",
    "timesteps_arr=conf['timesteps']\n",
    "\n",
    "bi_arr=conf['bidirectional']\n",
    "layer_arr=conf['layers']                                  \n",
    "units_arr=conf['units']        \n",
    "epochs_arr=conf['epochs']\n",
    "train_batch_arr=conf['train_batch']   \n",
    "\n",
    "l_ts=len(timesteps_arr)\n",
    "\n",
    "l_bi=len(bi_arr)\n",
    "l_layer =len(layer_arr)\n",
    "l_units=len(units_arr)\n",
    "l_epochs =len(epochs_arr)\n",
    "l_batch =len(train_batch_arr)\n",
    "n_iters=l_ts*l_bi*l_layer*l_units*l_epochs*l_batch\n",
    "# GT is in the shape (n_events x 2), a y output signal with the same length as x is required\n",
    "perf_train_arr=np.zeros(shape=(n_iters,len(th_arr),3)) # Performance array, (n_models x n_th x 3 ) [P R F1]\n",
    "perf_test_arr=np.zeros_like(perf_train_arr)\n",
    "timesteps_arr_ploting=[]            # Array that will be used in the validation, to be able to call the function predict\n",
    "\n",
    "print(f'{n_channels} channels will be used to train the LSTM models')\n",
    "\n",
    "print(f'{n_iters} models will be trained')\n",
    "\n",
    "x_test_or,GT_test,x_train_or,GT_train=aux_fcn.split_data(x_training,GT_training,split=0.7,sf=sf)\n",
    "\n",
    "y_test_or= np.zeros(shape=(len(x_test_or)))\n",
    "for ev in GT_test:\n",
    "    y_test_or[int(sf*ev[0]):int(sf*ev[1])]=1\n",
    "y_train_or= np.zeros(shape=(len(x_train_or)))\n",
    "for ev in GT_train:\n",
    "    y_train_or[int(sf*ev[0]):int(sf*ev[1])]=1\n",
    "\n",
    "\n",
    "for i_ts,timesteps in enumerate(timesteps_arr):\n",
    "\n",
    "        x_train=x_train_or[:len(x_train_or)-len(x_train_or)%timesteps].reshape(-1,timesteps,n_channels)\n",
    "        y_train=y_train_or[:len(y_train_or)-len(y_train_or)%timesteps].reshape(-1,timesteps,1)\n",
    "        \n",
    "        x_test=x_test_or[:len(x_test_or)-len(x_test_or)%timesteps].reshape(-1,timesteps,n_channels)\n",
    "        y_test=y_test_or[:len(y_test_or)-len(y_test_or)%timesteps].reshape(-1,timesteps,1)\n",
    "\n",
    "        for i_bi,bi in enumerate(bi_arr):\n",
    "                for i_layer,layers in enumerate(layer_arr):\n",
    "                    for i_units,units in enumerate(units_arr):\n",
    "                        for i_epochs,epochs in enumerate(epochs_arr):\n",
    "                            for i_batch,train_batch in enumerate(train_batch_arr):\n",
    "                                iter=((((i_ts*l_bi+i_bi)*l_layer+i_layer)*l_units+ i_units)*l_epochs + i_epochs)*l_batch + i_batch\n",
    "                                print(f\"\\nIteration {iter+1} out of {n_iters}\")\n",
    "                                print(f'Number of channels: {n_channels:d}, Time steps: {timesteps:d}, Bidirectional: {bi:d}\\nN of layers: {layers:d}, N of units: {units:d}, epochs: {epochs:d}, Samples per batch: {train_batch:d}')\n",
    "\n",
    "                                model=aux_fcn.build_LSTM(input_shape=(timesteps,n_channels),n_layers=layers,layer_size=units,bidirectional=bi)\n",
    "                                # Training\n",
    "                                model.fit(x_train, y_train, epochs=epochs,batch_size=train_batch,validation_data=(x_test,y_test), verbose=1)\n",
    "                                model_arr.append(model)\n",
    "\n",
    "                                # Prediction\n",
    "                                y_test_predict = model.predict(x_test,verbose=1).reshape(-1,1,1)\n",
    "                                y_train_predict= model.predict(x_train,verbose=1).reshape(-1,1,1)\n",
    "    \n",
    "                                for i,th in enumerate(th_arr):\n",
    "                                    # Test\n",
    "                                    ytest_pred_ind=aux_fcn.get_predictions_index(y_test_predict,th)/sf\n",
    "                                    perf_test_arr[iter,i]=aux_fcn.get_performance(ytest_pred_ind,GT_test,0)[0:3]\n",
    "                                    # Train\n",
    "                                    ytrain_pred_ind=aux_fcn.get_predictions_index(y_train_predict,th)/sf\n",
    "                                    perf_train_arr[iter,i]=aux_fcn.get_performance(ytrain_pred_ind,GT_train,0)[0:3]\n",
    "\n",
    "                                # Saving the model\n",
    "                                model_name=f\"LSTM_Ch{n_channels:d}_Ts{timesteps:03d}_Bi{bi:d}_L{layers:d}_U{units:02d}_E{epochs:02d}_TB{train_batch:04d}\"\n",
    "                                model.save(os.path.join(parent_dir,'explore_models',model_name))\n",
    "\n",
    "                                model_name_arr.append(model_name)\n",
    "                                timesteps_arr_ploting.append(timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "fig,axs=plt.subplots(n_iters,2,figsize=(10,2*n_iters),sharey='col',sharex='col')\n",
    "\n",
    "for i in range(n_iters):\n",
    "    axs[i,0].plot(perf_train_arr[i,:,0],perf_train_arr[i,:,1],'k.-')\n",
    "    axs[i,0].plot(perf_test_arr[i,:,0],perf_test_arr[i,:,1],'b.-')\n",
    "    axs[i,1].plot(th_arr,perf_train_arr[i,:,2],'k.-')\n",
    "    axs[i,1].plot(th_arr,perf_test_arr[i,:,2],'b.-')\n",
    "    axs[i,0].set_title(model_name_arr[i])\n",
    "    axs[i,0].set_ylabel('Precision')\n",
    "    axs[i,1].set_ylabel('F1')\n",
    "axs[-1,0].set_xlabel('Recall')\n",
    "axs[-1,1].set_xlabel('Threshold')\n",
    "axs[0,0].legend(['Training','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop iterating over the models\n",
    "fig,axs=plt.subplots(n_iters,2,figsize=(10,2*n_iters),sharey='col',sharex='col')\n",
    "for n_m,model in enumerate(model_arr):\n",
    "    F1_arr=np.zeros(shape=(len(x_val_list),len(th_arr))) #(n_val_sess x n_th) Array where the F1 val of each sesion will be stored\n",
    "    for n_sess,LFP in enumerate(x_val_list):\n",
    "        val_pred=rippl_AI.predict(LFP,sf=1250,arch='LSTM',new_model=model,n_channels=n_channels,n_timesteps=timesteps_arr_ploting[n_m])[0]\n",
    "        for i,th in enumerate(th_arr):\n",
    "            val_pred_ind=aux_fcn.get_predictions_index(val_pred,th)/sf\n",
    "            F1_arr[n_sess,i]=aux_fcn.get_performance(val_pred_ind,GT_val_list[n_sess],verbose=False)[2]\n",
    "    \n",
    "    axs[n_m,0].plot(th_arr,perf_train_arr[n_m,:,2],'k.-')\n",
    "    axs[n_m,0].plot(th_arr,perf_test_arr[n_m,:,2],'b.-')\n",
    "    for F1 in F1_arr:\n",
    "        axs[n_m,1].plot(th_arr,F1)\n",
    "    axs[n_m,1].plot(th_arr,np.mean(F1_arr,axis=0),'k.-')\n",
    "    axs[n_m,0].set_title(model_name_arr[n_m])\n",
    "    axs[n_m,0].set_ylabel('Precision')\n",
    "    axs[n_m,1].set_ylabel('F1')\n",
    "axs[-1,0].set_xlabel('Recall')\n",
    "axs[-1,1].set_xlabel('Threshold')\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PublicBCG_d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
