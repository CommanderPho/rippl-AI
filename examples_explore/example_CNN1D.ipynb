{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN1D parameter exploration\n",
    "This notebook is a template for finding the CNN1D model best suited for your needs\n",
    "\n",
    "This architecture is based in the CNN1D designed by A. Navas-Oliv√© (https://doi.org/10.7554/eLife.77772)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import importlib\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import sys\n",
    "parent_dir=os.path.dirname(os.getcwd())\n",
    "sys.path.insert(0,parent_dir)\n",
    "import rippl_AI\n",
    "import aux_fcn\n",
    "importlib.reload(aux_fcn)\n",
    "importlib.reload(rippl_AI)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data download\n",
    "4 uLED sessions will be downloaded: Amigo2 and Som2 will be used for training ; Dlx1 and Thy7 for validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from figshare.figshare.figshare import Figshare\n",
    "fshare = Figshare()\n",
    "\n",
    "article_ids = [16847521,16856137,14959449,14960085] \n",
    "sess=['Amigo2','Som2','Dlx1','Thy7']                                  \n",
    "for id,s in zip(article_ids,sess):\n",
    "    datapath = os.path.join(parent_dir,'Downloaded_data', f'{s}')\n",
    "    if os.path.isdir(datapath):\n",
    "        print(f\"{s} session already exists. Moving on.\")\n",
    "    else:\n",
    "        print(\"Downloading data... Please wait, this might take up some time\")        # Can take up to 10 minutes\n",
    "        fshare.retrieve_files_from_article(id,directory=datapath)\n",
    "        print(\"Data downloaded!\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data load\n",
    "The training sessions' LFP will be appended together in a list. The same will happen with the ripples detection times.\n",
    "That is the required input for the training parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training sessions will be appended together. Replace this cell with your own data loading\n",
    "train_LFPs=[]\n",
    "train_GTs=[]\n",
    "# Amigo2\n",
    "path=os.path.join(parent_dir,'Downloaded_data','Amigo2','figshare_16847521')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "train_LFPs.append(LFP)\n",
    "train_GTs.append(GT)\n",
    "# Som2\n",
    "path=os.path.join(parent_dir,'Downloaded_data','Som2','figshare_16856137')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "train_LFPs.append(LFP)\n",
    "train_GTs.append(GT)\n",
    "\n",
    "## Append all your validation sessions\n",
    "val_LFPs=[]\n",
    "val_GTs=[]\n",
    "# Dlx1 Validation\n",
    "path=os.path.join(parent_dir,'Downloaded_data','Dlx1','figshare_14959449')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "val_LFPs.append(LFP)\n",
    "val_GTs.append(GT)\n",
    "# Thy07 Validation\n",
    "path=os.path.join(parent_dir,'Downloaded_data','Thy7','figshare_14960085')\n",
    "LFP,GT=aux_fcn.load_lab_data(path)\n",
    "val_LFPs.append(LFP)\n",
    "val_GTs.append(GT)\n",
    "\n",
    "x_training,GT_training,x_val_list,GT_val_list=rippl_AI.prepare_training_data(train_LFPs,train_GTs,val_LFPs,val_GTs,sf=30000)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN1D training parameters"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Parameters:\n",
    "* Channels:  number of channels that will be used to train the model, extracted from the data shape defined in the previous cell\n",
    "* Timesteps: number of samples that the model will use to produce a single output\n",
    "* Configuration: list with as many elements as layers in the model shaped [number of kernels layers, kernel size and stride ]. The length size and the kernel layer were matched to reduce design complexity.\n",
    "* Epoch: number of times the training data set is used to train the model\n",
    "* Training batch: number of windows that are proccessed before weight updating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf= {\"timesteps\":   [16],        # 16, 32, 64 ...\n",
    "      \"configuration\":      [[[4,2],[2,1],[8,2],[4,1],[16,2],[8,1],[32,2]],  \n",
    "                     [[4,4],[2,1],[8,2],[4,1],[16,2],[8,1],[32,2]]],  \n",
    "      \"epochs\":      [1],         # 1, 2, 3, 5...\n",
    "      \"train_batch\": [2**5],      # 32, 64, 128...\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Desired sampling frequency of the models\n",
    "sf=1250\n",
    "th_arr=np.linspace(0.1,0.9,9)\n",
    "model_name_arr=[]           # To plot in the next cell\n",
    "model_arr=[]                # Actual model array, used in the next validation section\n",
    "n_channels=x_training.shape[1]\n",
    "timesteps_arr=conf['timesteps']\n",
    "\n",
    "config_arr=conf['configuration']\n",
    "epochs_arr=conf['epochs']\n",
    "train_batch_arr=conf['train_batch']   \n",
    "\n",
    "l_ts=len(timesteps_arr)\n",
    "l_conf=len(config_arr)\n",
    "l_epochs =len(epochs_arr)\n",
    "l_batch =len(train_batch_arr)\n",
    "n_iters=l_ts*l_conf*l_epochs*l_batch\n",
    "# GT is in the shape (n_events x 2), a y output signal with the same length as x is required\n",
    "perf_train_arr=np.zeros(shape=(n_iters,len(th_arr),3)) # Performance array, (n_models x n_th x 3 ) [P R F1]\n",
    "perf_test_arr=np.zeros_like(perf_train_arr)\n",
    "timesteps_arr_ploting=[]            # Array that will be used in the validation, to be able to call the function predict\n",
    "\n",
    "print(f'{n_channels} channels will be used to train the CNN1D models')\n",
    "\n",
    "print(f'{n_iters} models will be trained')\n",
    "\n",
    "x_test_or,GT_test,x_train_or,GT_train=aux_fcn.split_data(x_training,GT_training,split=0.7,sf=sf)\n",
    "\n",
    "y_test_or= np.zeros(shape=(len(x_test_or)))\n",
    "for ev in GT_test:\n",
    "    y_test_or[int(sf*ev[0]):int(sf*ev[1])]=1\n",
    "y_train_or= np.zeros(shape=(len(x_train_or)))\n",
    "for ev in GT_train:\n",
    "    y_train_or[int(sf*ev[0]):int(sf*ev[1])]=1\n",
    "\n",
    "\n",
    "for i_ts,timesteps in enumerate(timesteps_arr):\n",
    "    x_train=x_train_or[:len(x_train_or)-len(x_train_or)%timesteps].reshape(-1,timesteps,n_channels)\n",
    "    y_train_aux=y_train_or[:len(y_train_or)-len(y_train_or)%timesteps].reshape(-1,timesteps)\n",
    "    x_test=x_test_or[:len(x_test_or)-len(x_test_or)%timesteps].reshape(-1,timesteps,n_channels)\n",
    "    y_test_aux=y_test_or[:len(y_test_or)-len(y_test_or)%timesteps].reshape(-1,timesteps)\n",
    "\n",
    "    y_train=np.zeros(shape=[x_train.shape[0],1])\n",
    "    for i in range(y_train_aux.shape[0]):\n",
    "        y_train[i]=1  if any (y_train_aux[i]==1) else 0\n",
    "    print(\"Train Input and Output dimension\", x_train.shape,y_train.shape)\n",
    "    \n",
    "    y_test=np.zeros(shape=[x_test.shape[0],1])\n",
    "    for i in range(y_test_aux.shape[0]):\n",
    "        y_test[i]=1  if any (y_test_aux[i]==1) else 0\n",
    "\n",
    "    for i_conf, configuration in enumerate(config_arr):\n",
    "        for i_epochs,epochs in enumerate(epochs_arr):\n",
    "            for i_batch,train_batch in enumerate(train_batch_arr):\n",
    "                iter=((i_ts*l_conf+i_conf)*l_epochs + i_epochs)*l_batch + i_batch\n",
    "                print(f\"\\nIteration {iter+1} out of {n_iters}\")\n",
    "                print(f'Number of channels: {n_channels:d}, Time steps: {timesteps:d},\\nconfiguration: {configuration}\\nEpochs: {epochs:d}, Samples per batch: {train_batch:d}')\n",
    "\n",
    "                model = aux_fcn.build_CNN1D(n_channels,timesteps,configuration)\n",
    "                # Training\n",
    "                model.fit(x_train, y_train,shuffle=False, epochs=epochs,batch_size=train_batch,validation_data=(x_test,y_test), verbose=1)\n",
    "                model_arr.append(model)\n",
    "                # Prediction\n",
    "                test_signal = model.predict(x_test,verbose=1)\n",
    "                train_signal=model.predict(x_train,verbose=1)\n",
    "\n",
    "                y_train_predict=np.empty(shape=(x_train.shape[0]*timesteps,1,1))\n",
    "                for i,window in enumerate(train_signal):\n",
    "                    y_train_predict[i*timesteps:(i+1)*timesteps]=window\n",
    "                y_test_predict=np.empty(shape=(x_test.shape[0]*timesteps,1,1))\n",
    "                for i,window in enumerate(test_signal):\n",
    "                    y_test_predict[i*timesteps:(i+1)*timesteps]=window\n",
    "\n",
    "                ############################\n",
    "                for i,th in enumerate(th_arr):\n",
    "                    # Test\n",
    "                    ytest_pred_ind=aux_fcn.get_predictions_index(y_test_predict,th)/sf\n",
    "                    perf_test_arr[iter,i]=aux_fcn.get_performance(ytest_pred_ind,GT_test,0)[0:3]\n",
    "                    # Train\n",
    "                    ytrain_pred_ind=aux_fcn.get_predictions_index(y_train_predict,th)/sf\n",
    "                    perf_train_arr[iter,i]=aux_fcn.get_performance(ytrain_pred_ind,GT_train,0)[0:3]\n",
    "\n",
    "                    # Saving the model\n",
    "                    model_name=f\"CNN1D_Ch{n_channels:d}_Ts{timesteps:03d}_C{i_conf:02d}_E{epochs:02d}_TB{train_batch:04d}\"\n",
    "                    model.save(os.path.join(parent_dir,'explore_models',model_name))\n",
    "\n",
    "                    model_name_arr.append(model_name)\n",
    "                    timesteps_arr_ploting.append(timesteps)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training results\n",
    "fig,axs=plt.subplots(n_iters,2,figsize=(10,2*n_iters),sharey='col',sharex='col')\n",
    "\n",
    "for i in range(n_iters):\n",
    "    axs[i,0].plot(perf_train_arr[i,:,0],perf_train_arr[i,:,1],'k.-')\n",
    "    axs[i,0].plot(perf_test_arr[i,:,0],perf_test_arr[i,:,1],'b.-')\n",
    "    axs[i,1].plot(th_arr,perf_train_arr[i,:,2],'k.-')\n",
    "    axs[i,1].plot(th_arr,perf_test_arr[i,:,2],'b.-')\n",
    "    axs[i,0].set_title(model_name_arr[i])\n",
    "    axs[i,0].set_ylabel('Precision')\n",
    "    axs[i,1].set_ylabel('F1')\n",
    "axs[-1,0].set_xlabel('Recall')\n",
    "axs[-1,1].set_xlabel('Threshold')\n",
    "axs[0,0].legend(['Training','Test'])\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For loop iterating over the models\n",
    "fig,axs=plt.subplots(n_iters,2,figsize=(10,2*n_iters),sharey='col',sharex='col')\n",
    "for n_m,model in enumerate(model_arr):\n",
    "    F1_arr=np.zeros(shape=(len(x_val_list),len(th_arr))) #(n_val_sess x n_th) Array where the F1 val of each sesion will be stored\n",
    "    for n_sess,LFP in enumerate(x_val_list):\n",
    "        val_pred=rippl_AI.predict(LFP,sf=1250,arch='CNN1D',new_model=model,n_channels=n_channels,n_timesteps=timesteps_arr_ploting[n_m])[0]\n",
    "        for i,th in enumerate(th_arr):\n",
    "            val_pred_ind=aux_fcn.get_predictions_index(val_pred,th)/sf\n",
    "            F1_arr[n_sess,i]=aux_fcn.get_performance(val_pred_ind,GT_val_list[n_sess],verbose=False)[2]\n",
    "    \n",
    "    axs[n_m,0].plot(th_arr,perf_train_arr[n_m,:,2],'k.-')\n",
    "    axs[n_m,0].plot(th_arr,perf_test_arr[n_m,:,2],'b.-')\n",
    "    for F1 in F1_arr:\n",
    "        axs[n_m,1].plot(th_arr,F1)\n",
    "    axs[n_m,1].plot(th_arr,np.mean(F1_arr,axis=0),'k.-')\n",
    "    axs[n_m,0].set_title(model_name_arr[n_m])\n",
    "    axs[n_m,0].set_ylabel('Precision')\n",
    "    axs[n_m,1].set_ylabel('F1')\n",
    "axs[-1,0].set_xlabel('Recall')\n",
    "axs[-1,1].set_xlabel('Threshold')\n",
    "plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PublicBCG_d",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
